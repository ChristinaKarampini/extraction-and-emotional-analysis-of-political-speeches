import pandas as pd
import torch
from tqdm import tqdm
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Load CSV
file_path = "/content/drive/MyDrive/text_300_sample.csv"
df = pd.read_csv(file_path)

# Column containing text
text_column = "text"
texts = df[text_column].astype(str).tolist()

# Batch size (adjust if you get CUDA OOM)
batch_size = 16
max_length = 256

# Storage for results
results = {
    "stance": [],
    "frame": [],
    "intensity": [],
    "sentiment": [],
    "emotion": []
}

# Batched inference loop
for i in tqdm(range(0, len(texts), batch_size)):
    batch_texts = texts[i:i + batch_size]

    inputs = tokenizer(
        batch_texts,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=max_length
    )

    with torch.no_grad():
        outputs = model(**inputs)

    results["stance"].extend(outputs["stance"].argmax(dim=1).cpu().tolist())
    results["frame"].extend(outputs["frame"].argmax(dim=1).cpu().tolist())
    results["intensity"].extend(outputs["intensity"].argmax(dim=1).cpu().tolist())
    results["sentiment"].extend(outputs["sentiment"].argmax(dim=1).cpu().tolist())
    results["emotion"].extend(outputs["emotion"].argmax(dim=1).cpu().tolist())

# Add predictions to DataFrame
for key in results:
    df[key] = results[key]

#  Save results
output_path = "/content/drive/MyDrive/output_with_emotions_results.csv"
df.to_csv(output_path, index=False)

print("1. OK, Analysis complete!")
print("Saved to:", output_path)
df.head()
